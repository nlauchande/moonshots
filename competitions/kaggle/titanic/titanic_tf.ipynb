{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Step 1. Get the Data : Import and parse the data sets\n",
    "#Step 2. Feature Engineering : Create feature columns to describe the data\n",
    "#Step 3. Select ML Model : Select the type of model\n",
    "#Step 4. Train your model : Train the model\n",
    "#Step 5. Evaluate the model : Evaluate the model's effectiveness\n",
    "#Step 6. Roll out and let the model make predictions: Let the trained model make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the training inputs\n",
    "def get_train_inputs(batch_size, mnist_data):\n",
    "    \"\"\"Return the input function to get the training data.\n",
    "    Args:\n",
    "        batch_size (int): Batch size of training iterator that is returned\n",
    "                          by the input function.\n",
    "        mnist_data (Object): Object holding the loaded mnist data.\n",
    "    Returns:\n",
    "        (Input function, IteratorInitializerHook):\n",
    "            - Function that returns (features, labels) when called.\n",
    "            - Hook to initialise input iterator.\n",
    "    \"\"\"\n",
    "    iterator_initializer_hook = IteratorInitializerHook()\n",
    "\n",
    "    def train_inputs():\n",
    "        \"\"\"Returns training set as Operations.\n",
    "        Returns:\n",
    "            (features, labels) Operations that iterate over the dataset\n",
    "            on every evaluation\n",
    "        \"\"\"\n",
    "        with tf.name_scope('Training_data'):\n",
    "            # Get Mnist data\n",
    "            images = mnist_data.train.images.reshape([-1, 28, 28, 1])\n",
    "            labels = mnist_data.train.labels\n",
    "            # Define placeholders\n",
    "            images_placeholder = tf.placeholder(\n",
    "                images.dtype, images.shape)\n",
    "            labels_placeholder = tf.placeholder(\n",
    "                labels.dtype, labels.shape)\n",
    "            # Build dataset iterator\n",
    "            dataset = tf.contrib.data.Dataset.from_tensor_slices(\n",
    "                (images_placeholder, labels_placeholder))\n",
    "            dataset = dataset.repeat(None)  # Infinite iterations\n",
    "            dataset = dataset.shuffle(buffer_size=10000)\n",
    "            dataset = dataset.batch(batch_size)\n",
    "            iterator = dataset.make_initializable_iterator()\n",
    "            next_example, next_label = iterator.get_next()\n",
    "            # Set runhook to initialize iterator\n",
    "            iterator_initializer_hook.iterator_initializer_func = \\\n",
    "                lambda sess: sess.run(\n",
    "                    iterator.initializer,\n",
    "                    feed_dict={images_placeholder: images,\n",
    "                               labels_placeholder: labels})\n",
    "            # Return batched (features, labels)\n",
    "            return next_example, next_label\n",
    "\n",
    "    # Return function and hook\n",
    "    return train_inputs, iterator_initializer_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1' '0' '3' 'Braund, Mr. Owen Harris' 'male' '22' '1.1' '0.1' 'A/5 21171'\n",
      " '7.25' 'Unnamed: 10' 'S']\n"
     ]
    }
   ],
   "source": [
    "print(train_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.TextLineDataset('./train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_CSV_COLUMNS = [\n",
    "    'PassengerId','Survived','Pclass','Name','Sex','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TextLineDataset shapes: (), types: tf.string>\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_fn(data_file, num_epochs, shuffle, batch_size,test):\n",
    "  \"\"\"Generate an input function for the Estimator.\"\"\"\n",
    "  assert tf.gfile.Exists(data_file), (\n",
    "      '%s not found. Please make sure you have either run data_download.py or '\n",
    "      'set both arguments --train_data and --test_data.' % data_file)\n",
    "\n",
    "  def parse_csv_test(value):\n",
    "    print('Parsing', data_file)\n",
    "    columns = tf.decode_csv(value, record_defaults= [ [''],['Pclass'],[''],[''],[-1.0],[-1],[-1],[''],[0.0],[''],['']])\n",
    "    features = dict(zip(_CSV_COLUMNS, columns))\n",
    "    print(str(features.keys))\n",
    "    return features\n",
    "\n",
    "    \n",
    "  def parse_csv(value):\n",
    "    print('Parsing', data_file)\n",
    "    columns = tf.decode_csv(value, record_defaults= [ [''],[0],['Pclass'],[''],[''],[-1.0],[-1],[-1],[''],[0.0],[''],['']])\n",
    "    features = dict(zip(_CSV_COLUMNS, columns))\n",
    "    print(str(features.keys))\n",
    "    labels = features.pop('Survived')\n",
    "    return features, labels\n",
    "\n",
    "  # Extract lines from input files using the Dataset API.\n",
    "  dataset = tf.data.TextLineDataset(data_file).skip(1)\n",
    "\n",
    "  if test==False:\n",
    "    dataset = dataset.map(parse_csv)\n",
    "  else:\n",
    "    dataset = dataset.map(parse_csv_test)\n",
    "    \n",
    "\n",
    "  # We call repeat after shuffling, rather than before, to prevent separate\n",
    "  # epochs from blending together.\n",
    "  dataset = dataset.repeat(num_epochs)\n",
    "  dataset = dataset.batch(batch_size)\n",
    "\n",
    "  iterator = dataset.make_one_shot_iterator()\n",
    "  features, labels = iterator.get_next()\n",
    "  return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Questions :\n",
    "#1. Why do you need epochs when you are reading a file ?\n",
    "#2. Why do you need batch size when reading the file ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Parsing', './train.csv')\n",
      "<built-in method keys of dict object at 0x1813a7c910>\n"
     ]
    }
   ],
   "source": [
    "features, labels = input_fn('./train.csv', 10, False, 10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/yk/xmj889zj7q353d_cn3k5kqrr9h03ws/T/tmp7A_Phw\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x181265a050>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/var/folders/yk/xmj889zj7q353d_cn3k5kqrr9h03ws/T/tmp7A_Phw', '_save_summary_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.LinearClassifier(\n",
    "    feature_columns=[\n",
    "    tf.feature_column.categorical_column_with_hash_bucket('Pclass',hash_bucket_size=50 ),\n",
    "    tf.feature_column.categorical_column_with_hash_bucket('Sex', hash_bucket_size=2),\n",
    "    tf.feature_column.numeric_column('Age'),\n",
    "    tf.feature_column.numeric_column('SibSp'),\n",
    "    tf.feature_column.numeric_column('Parch'),\n",
    "    tf.feature_column.numeric_column('Fare'),\n",
    "    tf.feature_column.categorical_column_with_hash_bucket('Cabin', hash_bucket_size=4),\n",
    "    tf.feature_column.categorical_column_with_hash_bucket('Embarked', hash_bucket_size=3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Parsing', './train.csv')\n",
      "<built-in method keys of dict object at 0x1812075e88>\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/yk/xmj889zj7q353d_cn3k5kqrr9h03ws/T/tmp7A_Phw/model.ckpt-891\n",
      "INFO:tensorflow:Saving checkpoints for 892 into /var/folders/yk/xmj889zj7q353d_cn3k5kqrr9h03ws/T/tmp7A_Phw/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.2212, step = 892\n",
      "INFO:tensorflow:global_step/sec: 126.836\n",
      "INFO:tensorflow:loss = 5.61128, step = 992 (0.789 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.214\n",
      "INFO:tensorflow:loss = 5.922, step = 1092 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.948\n",
      "INFO:tensorflow:loss = 3.21539, step = 1192 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.835\n",
      "INFO:tensorflow:loss = 4.75093, step = 1292 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.577\n",
      "INFO:tensorflow:loss = 6.59031, step = 1392 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.121\n",
      "INFO:tensorflow:loss = 7.64318, step = 1492 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.366\n",
      "INFO:tensorflow:loss = 4.32773, step = 1592 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.491\n",
      "INFO:tensorflow:loss = 1.50275, step = 1692 (0.316 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1782 into /var/folders/yk/xmj889zj7q353d_cn3k5kqrr9h03ws/T/tmp7A_Phw/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3.77915.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x1812ee4050>"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(input_fn=lambda: input_fn('./train.csv', 10, False, 10, False), steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Parsing', './test.csv')\n",
      "<built-in method keys of dict object at 0x1812a177f8>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-246-0e7d1d6e23c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./test.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/natu.lauchande/anaconda2/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, input_fn, steps, hooks, checkpoint_path, name)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_convert_eval_steps_to_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/natu.lauchande/anaconda2/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36m_evaluate_model\u001b[0;34m(self, input_fn, hooks, checkpoint_path, name)\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_and_assert_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m       features, labels = self._get_features_and_labels_from_input_fn(\n\u001b[0;32m--> 808\u001b[0;31m           input_fn, model_fn_lib.ModeKeys.EVAL)\n\u001b[0m\u001b[1;32m    809\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[1;32m    810\u001b[0m           features, labels, model_fn_lib.ModeKeys.EVAL, self.config)\n",
      "\u001b[0;32m/Users/natu.lauchande/anaconda2/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36m_get_features_and_labels_from_input_fn\u001b[0;34m(self, input_fn, mode)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_features_and_labels_from_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/natu.lauchande/anaconda2/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36m_call_input_fn\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    661\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/cpu:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-246-0e7d1d6e23c1>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./test.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-237-063ba5078949>\u001b[0m in \u001b[0;36minput_fn\u001b[0;34m(data_file, num_epochs, shuffle, batch_size, test)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_one_shot_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack"
     ]
    }
   ],
   "source": [
    "results = classifier.evaluate(input_fn=lambda: input_fn('./test.csv', 10, False, 10, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "input_fn() takes exactly 5 arguments (4 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-247-c6eb7ff37cbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpred_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./test.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/natu.lauchande/anaconda2/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_fn, predict_keys, hooks, checkpoint_path)\u001b[0m\n\u001b[1;32m    407\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_and_assert_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m       features = self._get_features_from_input_fn(\n\u001b[0;32m--> 409\u001b[0;31m           input_fn, model_fn_lib.ModeKeys.PREDICT)\n\u001b[0m\u001b[1;32m    410\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[1;32m    411\u001b[0m           features, None, model_fn_lib.ModeKeys.PREDICT, self.config)\n",
      "\u001b[0;32m/Users/natu.lauchande/anaconda2/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36m_get_features_from_input_fn\u001b[0;34m(self, input_fn, mode)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_features_from_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQUEUE_RUNNERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m       logging.warning('Input graph does not contain a QueueRunner. '\n",
      "\u001b[0;32m/Users/natu.lauchande/anaconda2/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36m_call_input_fn\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    661\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/cpu:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-247-c6eb7ff37cbd>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./test.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: input_fn() takes exactly 5 arguments (4 given)"
     ]
    }
   ],
   "source": [
    "pred_iter = classifier.predict(input_fn=lambda: input_fn(\"./test.csv\", 1, False, 1))\n",
    "for pred in pred_iter:\n",
    "    print(pred['classes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "estimators",
   "language": "python",
   "name": "estimators"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
